{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODlkxF1u490J9IDZDCG+TU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esintao/Konrad-og-Esin/blob/main/Chain_of_thought.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DHFwdkX2McCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e78fb9-0793-4dfe-8c87-28ac19738f0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model"
      ],
      "metadata": {
        "id": "Hb5VBBORMw_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Write an email about an alpaca that likes flan\"\n",
        "\n",
        "model = pipeline(task=\"text2text-generation\", model=\"google/flan-t5-base\")\n",
        "\n",
        "model(prompt, max_length=128, do_sample=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aONQLLOkMkBn",
        "outputId": "7b7b70a2-391e-4944-d87d-59913fc3f332"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Both `max_new_tokens` (=256) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"Alpaca: I have an alpaca that likes flan. He's a very small one and he's a very small one. He's a very small one and he's a very small one. He's a very small one and he's a very small one. He's a very small one and he's a very small one. He's a very small one and he's a very small one. He's a very small one and he's a very small one. He's a very small one and he's a very small one. He's a very small one and he's a very small one. He's a very small one and he's a very small one. He's a very small one and he's a very small one. He's a very small one and he's a very small one. He's a very small one and he's a very small one. He's a very small one and he'\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset"
      ],
      "metadata": {
        "id": "W6UXmWNOMzTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Jp08Zz7cOeHD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"derek-thomas/ScienceQA\")\n",
        "\n",
        "df = pd.DataFrame.from_dict(dataset['train'])\n",
        "\n",
        "df = df[(df['choices'].str.len() == 4) & (df['image'].isna())]\n",
        "\n",
        "df = df.sample(n=200)\n",
        "\n"
      ],
      "metadata": {
        "id": "-3vpWHVWMweN"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompting without CoT"
      ],
      "metadata": {
        "id": "Zz27mtA7Wwzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answers = []\n",
        "question_list = []\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    question_text = (\n",
        "        f\"Question: {row['question']}\\n\"\n",
        "        f\"(A) {row['choices'][0]} \"\n",
        "        f\"(B) {row['choices'][1]} \"\n",
        "        f\"(C) {row['choices'][2]} \"\n",
        "        f\"(D) {row['choices'][3]}\"\n",
        "        f\"The answer must be formatted as 1 letter, A-D.\"\n",
        "    )\n",
        "\n",
        "    answers.append(model(question_text, max_new_tokens=1, do_sample=False))\n",
        "    question_list.append(question_text)\n",
        "\n",
        "answers[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1tVp7cuSzeJ",
        "outputId": "6d61a9b3-3c3c-49b3-ef57-56295c1e55db"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'A'}]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_list[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "UXi7XtRaU6IG",
        "outputId": "65484f32-56e9-4130-d35f-a0833f521765"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Question: How long is a rowboat?\\n(A) 3 centimeters (B) 3 kilometers (C) 3 meters (D) 3 millimetersThe answer must be formatted as 1 letter, A-D.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompting with CoT"
      ],
      "metadata": {
        "id": "4lkvFKnyW0xA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answers_CoT = []\n",
        "question_list_CoT = []\n",
        "\n",
        "df = df.sample(n=1)\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    # Constructing a clearly formatted prompt\n",
        "    question_text_CoT = (\n",
        "        \"You are a careful reasoning assistant that answers multiple-choice questions about science. \"\n",
        "        \"First, think step by step. Then, give the final answer. \"\n",
        "        \"Format exactly as:\\n\"\n",
        "        \"Reasoning: <step 1>\\n\"\n",
        "        \"Reasoning: <step 2>\\n\"\n",
        "        \"Reasoning: <step 3>\\n\"\n",
        "        \"Answer: <final letter>\\n\\n\"\n",
        "        f\"Question: {row['question']}\\n\"\n",
        "        f\"(A) {row['choices'][0]}\\n\"\n",
        "        f\"(B) {row['choices'][1]}\\n\"\n",
        "        f\"(C) {row['choices'][2]}\\n\"\n",
        "        f\"(D) {row['choices'][3]}\\n\\n\"\n",
        "        \"Give three reasoning steps and at last the answer:\" # This nudge helps the model start correctly\n",
        "    )\n",
        "\n",
        "    # Use a higher max_new_tokens to allow for reasoning steps\n",
        "    output = model(question_text_CoT, max_new_tokens=300, do_sample=False)\n",
        "    answers_CoT.append(output)\n",
        "    question_list_CoT.append(question_text_CoT)\n",
        "\n",
        "answers_CoT[0]\n",
        "\n"
      ],
      "metadata": {
        "id": "q1YHthT8Wz7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_list_CoT[0]"
      ],
      "metadata": {
        "id": "w0uIau8LXa2i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}